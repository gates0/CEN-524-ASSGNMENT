{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c2e9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"synthetic_backend_performance_data.csv\")\n",
    "\n",
    "# 1. Construct design matrix (Add bias term)\n",
    "X = df[['Tickets_Handled']].values\n",
    "X = np.hstack([np.ones((X.shape[0], 1)), X])  # Add bias column\n",
    "\n",
    "# Output vector\n",
    "y = df['Performance_Improvement_Percentage'].values.reshape(-1, 1)\n",
    "\n",
    "# 2. Normalize (feature scaling)\n",
    "X_mean = X[:, 1].mean()\n",
    "X_std = X[:, 1].std()\n",
    "X[:, 1] = (X[:, 1] - X_mean) / X_std\n",
    "\n",
    "# Save normalized matrix for GitHub upload\n",
    "normalized_df = pd.DataFrame(X, columns=['Bias', 'Normalized_Tickets_Handled'])\n",
    "normalized_df['Performance_Improvement_Percentage'] = y\n",
    "normalized_df.to_csv(\"normalized_design_matrix.csv\", index=False)\n",
    "\n",
    "# 3. Cost Function\n",
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    predictions = X @ theta\n",
    "    cost = (1 / (2 * m)) * np.sum((predictions - y) ** 2)\n",
    "    return cost\n",
    "\n",
    "# 4. Gradient Descent\n",
    "def gradient_descent(X, y, theta, alpha, iterations):\n",
    "    m = len(y)\n",
    "    cost_history = []\n",
    "\n",
    "    for _ in range(iterations):\n",
    "        predictions = X @ theta\n",
    "        errors = predictions - y\n",
    "        theta -= (alpha / m) * (X.T @ errors)\n",
    "        cost_history.append(compute_cost(X, y, theta))\n",
    "\n",
    "    return theta, cost_history\n",
    "\n",
    "# Initialize theta, learning rate, iterations\n",
    "theta = np.zeros((2, 1))\n",
    "alpha = 0.1\n",
    "iterations = 1000\n",
    "\n",
    "# Train model\n",
    "theta_final, cost_history = gradient_descent(X, y, theta, alpha, iterations)\n",
    "\n",
    "# Plot cost over iterations\n",
    "plt.plot(range(iterations), cost_history)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Cost Function Convergence')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print final theta\n",
    "print(\"Trained Theta (weights):\", theta_final.ravel())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
